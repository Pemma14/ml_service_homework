import json
import csv
import io
import re
from typing import Dict, Any, List, Tuple
import pandas as pd
import streamlit as st
from webview.core.config import ALIAS_MAP, REQUIRED_ALIAS_ORDER, STATUS_MAP, SYNONYMS_MAP, MAX_AGE, MIN_AGE


def is_valid_url(url: str) -> bool:
    """–í–∞–ª–∏–¥–∏—Ä—É–µ—Ç URL-–∞–¥—Ä–µ—Å."""
    if not url or not isinstance(url, str):
        return False
    pattern = re.compile(
        r'^https?://'  # http:// or https://
        r'(?:(?:[A-Z0-9](?:[A-Z0-9-]{0,61}[A-Z0-9])?\.)+[A-Z]{2,6}\.?|'  # domain...
        r'localhost|'  # localhost...
        r'\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3})'  # ...or ip
        r'(?::\d+)?'  # optional port
        r'(?:/?|[/?]\S+)$', re.IGNORECASE)
    return bool(pattern.match(url))


@st.cache_data
def to_alias_keys(row: Dict[str, Any]) -> Dict[str, Any]:
    """–ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç –∫–ª—é—á–∏ –≤ —Ä—É—Å—Å–∫–∏–µ –∞–ª–∏–∞—Å—ã, –∏—Å–ø–æ–ª—å–∑—É—è —É–º–Ω—ã–π –ø–æ–∏—Å–∫ (—Å–∏–Ω–æ–Ω–∏–º—ã)."""
    out = {}

    # –°–Ω–∞—á–∞–ª–∞ –ø–æ–¥–≥–æ—Ç–æ–≤–∏–º –∫–∞—Ä—Ç—É: –æ—á–∏—â–µ–Ω–Ω—ã–π –∫–ª—é—á –≤ –Ω–∏–∂–Ω–µ–º —Ä–µ–≥–∏—Å—Ç—Ä–µ -> –∫–∞–Ω–æ–Ω–∏—á–µ—Å–∫–∏–π –∞–ª–∏–∞—Å
    # –≠—Ç–æ –º–æ–∂–Ω–æ –±—ã–ª–æ –±—ã –∫—ç—à–∏—Ä–æ–≤–∞—Ç—å –æ—Ç–¥–µ–ª—å–Ω–æ, –Ω–æ –¥–ª—è –ø—Ä–æ—Å—Ç–æ—Ç—ã —Å–¥–µ–ª–∞–µ–º —Ç—É—Ç
    key_to_canonical = {}
    for canonical, synonyms in SYNONYMS_MAP.items():
        for syn in synonyms:
            key_to_canonical[syn.lower().strip()] = canonical
        # –°–∞–º –∫–∞–Ω–æ–Ω–∏—á–µ—Å–∫–∏–π –≤–∞—Ä–∏–∞–Ω—Ç —Ç–æ–∂–µ –¥–æ–±–∞–≤–∏–º –Ω–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π
        key_to_canonical[canonical.lower().strip()] = canonical

    for k, v in row.items():
        # –û—á–∏—â–∞–µ–º –≤—Ö–æ–¥—è—â–∏–π –∫–ª—é—á
        clean_k = str(k).lower().strip()

        # 1. –ü—Ä—è–º–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ —Å –∫–∞–Ω–æ–Ω–∏—á–µ—Å–∫–∏–º –∞–ª–∏–∞—Å–æ–º (—É–∂–µ –µ—Å—Ç—å –≤ key_to_canonical)
        # 2. –ü–æ–∏—Å–∫ —á–µ—Ä–µ–∑ —Å–∏–Ω–æ–Ω–∏–º—ã
        canonical = key_to_canonical.get(clean_k)
        if canonical:
            out[canonical] = v
        else:
            # 3. –°—Ç–∞—Ä—ã–π –º–µ—Ö–∞–Ω–∏–∑–º —á–µ—Ä–µ–∑ ALIAS_MAP
            alias = ALIAS_MAP.get(k)
            if alias:
                out[alias] = v
            else:
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–∞–∫ –µ—Å—Ç—å, –µ—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π
                out[k] = v
    return out


@st.cache_data
def coerce_number(val) -> Tuple[bool, float | int | None]:
    """–ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç –∑–Ω–∞—á–µ–Ω–∏–µ –≤ —á–∏—Å–ª–æ, –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—è —Ç–µ–∫—Å—Ç–æ–≤—ã–µ —Å—Ç–∞—Ç—É—Å—ã."""
    if val is None:
        return False, None

    if isinstance(val, (int, float)):
        return True, val

    if isinstance(val, str):
        s = val.strip().lower()
        if not s:
            return False, None

        # –ü–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–µ —Å—Ç–∞—Ç—É—Å—ã
        if s in ("–µ—Å—Ç—å", "–≤—ã—è–≤–ª–µ–Ω", "–¥–∞", "–ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É–µ—Ç", "–ø—Ä–∏–Ω–∏–º–∞–µ—Ç", "1", "1.0", "true", "yes"):
            return True, 1
        # –û—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–µ —Å—Ç–∞—Ç—É—Å—ã
        if s in ("–Ω–µ—Ç", "–Ω–µ –≤—ã—è–≤–ª–µ–Ω", "–æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç", "–Ω–µ –ø—Ä–∏–Ω–∏–º–∞–µ—Ç", "0", "0.0", "false", "no"):
            return True, 0

        try:
            if "." in s or "," in s:
                return True, float(s.replace(",", "."))
            return True, int(s)
        except Exception:
            return False, None

    return False, None


@st.cache_data
def validate_item(item: Dict[str, Any]) -> Tuple[bool, Dict[str, str], Dict[str, Any], List[str]]:
    """
    –í–∞–ª–∏–¥–∏—Ä—É–µ—Ç –æ–¥–∏–Ω –æ–±—ä–µ–∫—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è ML-–∑–∞–ø—Ä–æ—Å–∞.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (is_valid, errors_by_field, normalized_item, warnings).
    """
    errs: Dict[str, str] = {}
    warnings: List[str] = []
    norm = to_alias_keys(item)

    # ‚Ññ –ü–∞—Ü–∏–µ–Ω—Ç–∞
    p_id = norm.get("‚Ññ –ü–∞—Ü–∏–µ–Ω—Ç–∞")
    if p_id is not None and str(p_id).strip():
        norm["‚Ññ –ü–∞—Ü–∏–µ–Ω—Ç–∞"] = str(p_id)
    else:
        norm["‚Ññ –ü–∞—Ü–∏–µ–Ω—Ç–∞"] = None

    # –í–æ–∑—Ä–∞—Å—Ç: MIN_AGE..MAX_AGE
    ok, num = coerce_number(norm.get("–í–æ–∑—Ä–∞—Å—Ç"))
    if not ok or num is None:
        errs["–í–æ–∑—Ä–∞—Å—Ç"] = "–ß–∏—Å–ª–æ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ"
    else:
        try:
            num_f = float(num)
            if not (MIN_AGE <= num_f <= MAX_AGE):
                errs["–í–æ–∑—Ä–∞—Å—Ç"] = f"–ó–Ω–∞—á–µ–Ω–∏–µ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –≤ –¥–∏–∞–ø–∞–∑–æ–Ω–µ {MIN_AGE}..{MAX_AGE}"
            norm["–í–æ–∑—Ä–∞—Å—Ç"] = num_f
        except Exception:
            errs["–í–æ–∑—Ä–∞—Å—Ç"] = "–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç"

    # –ë–∏–Ω–∞—Ä–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
    binary_cols = [
        "–í–ù–ù/–ü–ü",
        "–ö–ª–æ–∑–∞–ø–∏–Ω",
        "CYP2C19 1/2",
        "CYP2C19 1/17",
        "CYP2C19 *17/*17",
        "CYP2D6 1/3",
    ]

    for key in binary_cols:
        val = norm.get(key)
        if val is None or (isinstance(val, str) and not val.strip()):
            norm[key] = 0
            warnings.append(key)
            continue

        ok, num = coerce_number(val)
        if not ok or num is None:
            errs[key] = "–î–æ–ø—É—Å—Ç–∏–º—ã 0/1 –∏–ª–∏ —Å—Ç–∞—Ç—É—Å—ã (–î–∞/–ù–µ—Ç)"
        else:
            try:
                iv = int(num)
                if iv not in (0, 1):
                    errs[key] = "–î–æ–ø—É—Å—Ç–∏–º—ã —Ç–æ–ª—å–∫–æ 0 –∏–ª–∏ 1"
                norm[key] = iv
            except Exception:
                errs[key] = "–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç"

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö –∫–æ–ª–æ–Ω–æ–∫ –∏–∑ REQUIRED_ALIAS_ORDER
    for col in REQUIRED_ALIAS_ORDER:
        if col not in norm:
            norm[col] = 0
            if col == "–í–æ–∑—Ä–∞—Å—Ç":
                errs["–í–æ–∑—Ä–∞—Å—Ç"] = "–ü–æ–ª–µ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç"
            else:
                warnings.append(col)

    return len(errs) == 0, errs, norm, list(set(warnings))


def parse_uploaded_file(file_or_list) -> List[Dict[str, Any]]:
    """–ü–∞—Ä—Å–∏—Ç –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –∏–ª–∏ —Å–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤ (JSON, CSV –∏–ª–∏ Excel)."""
    if isinstance(file_or_list, list):
        all_data = []
        for f in file_or_list:
            all_data.extend(parse_uploaded_file(f))
        return all_data

    file = file_or_list
    name = (file.name or "").lower()
    content = file.read()
    file.seek(0)

    if name.endswith(".json"):
        data = json.loads(content.decode("utf-8"))
        if isinstance(data, dict):
            data = [data]
        if not isinstance(data, list):
            raise ValueError("–û–∂–∏–¥–∞–ª—Å—è —Å–ø–∏—Å–æ–∫ –æ–±—ä–µ–∫—Ç–æ–≤ JSON")
        return data

    if name.endswith(".csv"):
        text = content.decode("utf-8")
        f = io.StringIO(text)
        reader = csv.DictReader(f)
        return list(reader)

    if name.endswith((".xlsx", ".xls")):
        try:
            df = pd.read_excel(file)
            # –ó–∞–º–µ–Ω—è–µ–º NaN –Ω–∞ None –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–π —Ä–∞–±–æ—Ç—ã JSON API
            return df.where(pd.notnull(df), None).to_dict(orient="records")
        except ImportError:
            raise ImportError("–î–ª—è —Ä–∞–±–æ—Ç—ã —Å Excel —É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –±–∏–±–ª–∏–æ—Ç–µ–∫—É openpyxl: pip install openpyxl")
        except Exception as e:
            raise ValueError(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ Excel: {e}")

    # –ü–æ–ø—ã—Ç–∫–∞ –∞–≤—Ç–æ-–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è JSON
    try:
        data = json.loads(content.decode("utf-8"))
        return data if isinstance(data, list) else [data]
    except Exception:
        raise ValueError("–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è —Ñ–∞–π–ª—ã CSV, JSON –∏–ª–∏ Excel")


def parse_tsv(text: str) -> List[Dict[str, Any]]:
    """–ü–∞—Ä—Å–∏—Ç —Ç–µ–∫—Å—Ç –≤ —Ñ–æ—Ä–º–∞—Ç–µ TSV (–æ–±—ã—á–Ω–æ –ø—Ä–∏ –≤—Å—Ç–∞–≤–∫–µ –∏–∑ Excel)."""
    if not text or not text.strip():
        return []

    f = io.StringIO(text.strip())
    # Excel –ø—Ä–∏ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —Ç–∞–±—É–ª—è—Ü–∏—é –∫–∞–∫ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å
    reader = csv.DictReader(f, delimiter='\t')
    return list(reader)


def create_excel_template() -> bytes:
    """–°–æ–∑–¥–∞–µ—Ç –±–∞–π—Ç—ã –ø—É—Å—Ç–æ–≥–æ Excel-—Ñ–∞–π–ª–∞ —Å –∑–∞–≥–æ–ª–æ–≤–∫–∞–º–∏."""
    df = pd.DataFrame(columns=REQUIRED_ALIAS_ORDER)
    # –î–æ–±–∞–≤–∏–º –æ–¥–Ω—É —Å—Ç—Ä–æ–∫—É-–ø—Ä–∏–º–µ—Ä
    example_row = {
        "‚Ññ –ü–∞—Ü–∏–µ–Ω—Ç–∞": "–ü-101",
        "–í–æ–∑—Ä–∞—Å—Ç": 35,
        "–í–ù–ù/–ü–ü": 1,
        "–ö–ª–æ–∑–∞–ø–∏–Ω": 0,
        "CYP2C19 1/2": 0,
        "CYP2C19 1/17": 1,
        "CYP2C19 *17/*17": 0,
        "CYP2D6 1/3": 0,
    }
    df = pd.concat([df, pd.DataFrame([example_row])], ignore_index=True)
    return create_excel_download(df, sheet_name='Template')


def create_excel_download(df: pd.DataFrame, sheet_name: str = "Data") -> bytes:
    """–°–æ–∑–¥–∞–µ—Ç –±–∞–π—Ç—ã Excel-—Ñ–∞–π–ª–∞ –∏–∑ DataFrame."""
    output = io.BytesIO()
    try:
        with pd.ExcelWriter(output, engine='openpyxl') as writer:
            df.to_excel(writer, index=False, sheet_name=sheet_name)
        return output.getvalue()
    except ImportError:
        raise ImportError("–î–ª—è —Ä–∞–±–æ—Ç—ã —Å Excel —É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –±–∏–±–ª–∏–æ—Ç–µ–∫—É openpyxl: pip install openpyxl")
    except Exception as e:
        raise ValueError(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ Excel: {e}")


def prepare_results_df(input_data: List[Dict[str, Any]], prediction: Any, status: str = None) -> pd.DataFrame:
    """–û–±—ä–µ–¥–∏–Ω—è–µ—Ç –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –≤ –æ–¥–∏–Ω DataFrame."""
    if not input_data:
        return pd.DataFrame()

    df = pd.DataFrame(input_data)

    # –ü—ã—Ç–∞–µ–º—Å—è —Å–æ–ø–æ—Å—Ç–∞–≤–∏—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Å—Ç—Ä–æ–∫–∞–º
    if prediction is not None:
        if isinstance(prediction, list):
            if len(prediction) == len(df):
                df["–†–µ–∑—É–ª—å—Ç–∞—Ç"] = prediction
            else:
                # –ï—Å–ª–∏ —Å–ø–∏—Å–æ–∫, –Ω–æ –¥–ª–∏–Ω–∞ –Ω–µ —Å–æ–≤–ø–∞–¥–∞–µ—Ç, –ø—Ä–µ–≤—Ä–∞—â–∞–µ–º –≤ —Å—Ç—Ä–æ–∫—É
                df["–†–µ–∑—É–ª—å—Ç–∞—Ç"] = str(prediction)
        else:
            # –û–¥–∏–Ω–æ—á–Ω–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –¥–ª—è –≤—Å–µ—Ö —Å—Ç—Ä–æ–∫
            df["–†–µ–∑—É–ª—å—Ç–∞—Ç"] = prediction

    # –£–ø–æ—Ä—è–¥–æ—á–∏–≤–∞–µ–º –∫–æ–ª–æ–Ω–∫–∏: ‚Ññ–ø–∞—Ü–∏–µ–Ω—Ç–∞ –ø–µ—Ä–≤—ã–º, –†–µ–∑—É–ª—å—Ç–∞—Ç –ø–æ—Å–ª–µ–¥–Ω–∏–º
    cols = [c for c in REQUIRED_ALIAS_ORDER if c in df.columns]
    cols += [c for c in df.columns if c not in cols and c != "–†–µ–∑—É–ª—å—Ç–∞—Ç"]
    if "–†–µ–∑—É–ª—å—Ç–∞—Ç" in df.columns:
        cols.append("–†–µ–∑—É–ª—å—Ç–∞—Ç")

    return df[cols]


@st.cache_data
def status_label(status: str) -> str:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫—Ä–∞—Å–∏–≤—É—é –º–µ—Ç–∫—É –¥–ª—è —Å—Ç–∞—Ç—É—Å–∞."""
    s_l = (status or "").lower()
    status_info = STATUS_MAP.get(s_l, {"label": status, "icon": "‚¨ú"})
    return f"{status_info['icon']} {status_info['label']}"


def show_prediction_result(res: Any) -> None:
    """–û—Ç–æ–±—Ä–∞–∂–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è."""
    with st.container(border=True):
        st.markdown("#### üéØ –†–µ–∑—É–ª—å—Ç–∞—Ç –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è")
        if isinstance(res, dict):
            pred = res.get("prediction")
            if pred is not None:
                if isinstance(pred, list):
                    st.markdown("**–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è:**")
                    for i, v in enumerate(pred, 1):
                        st.write(f"‚Ä¢ –û–±—ä–µ–∫—Ç {i}: `{v}`")
                else:
                    st.write(pred)

            # –°–ª—É–∂–µ–±–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è (ID –∑–∞–ø—Ä–æ—Å–∞ –∏ –ø—Ä–∏–º–µ—á–∞–Ω–∏–µ —É–¥–∞–ª–µ–Ω—ã –ø–æ –ø—Ä–æ—Å—å–±–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è)
            meta_lines = []
            if "status" in res:
                meta_lines.append(f"**–°—Ç–∞—Ç—É—Å:** {status_label(str(res['status']))}")
            if "message" in res:
                meta_lines.append(f"**–°–æ–æ–±—â–µ–Ω–∏–µ:** {res['message']}")
            if "cost" in res:
                meta_lines.append(f"**–°—Ç–æ–∏–º–æ—Å—Ç—å:** {res['cost']} –∫—Ä–µ–¥–∏—Ç–æ–≤")
            if meta_lines:
                st.markdown("---")
                for line in meta_lines:
                    st.markdown(line)
        elif isinstance(res, list):
            st.markdown("**–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è:**")
            for i, v in enumerate(res, 1):
                st.write(f"‚Ä¢ –û–±—ä–µ–∫—Ç {i}: `{v}`")
        else:
            st.info(res)


@st.cache_data(show_spinner=False)
def requests_to_df(items: List[dict]) -> pd.DataFrame:
    """–ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç —Å–ø–∏—Å–æ–∫ –∑–∞–ø—Ä–æ—Å–æ–≤ –≤ DataFrame –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è."""
    if not items:
        return pd.DataFrame()

    df = pd.DataFrame(items)

    # –ò–∑–≤–ª–µ—á—ë–º –Ω–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏
    if "ml_model" in df.columns:
        df["model_name"] = df["ml_model"].apply(
            lambda x: (x or {}).get("name") if isinstance(x, dict) else None
        )

    # –ß–∏—Ç–∞–µ–º–∞—è –¥–∞—Ç–∞
    if "created_at" in df.columns:
        df["created_at"] = pd.to_datetime(df["created_at"]).dt.strftime("%Y-%m-%d %H:%M")

    # –ö—Ä–∞—Å–∏–≤—ã–π —Å—Ç–∞—Ç—É—Å
    if "status" in df.columns:
        df["status_label"] = df["status"].apply(lambda s: status_label(str(s)))

    # –í—ã–±–∏—Ä–∞–µ–º –Ω—É–∂–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏
    cols = [c for c in [
        "id", "created_at", "status_label", "cost", "model_name", "prediction"
    ] if c in df.columns]

    return df[cols].rename(columns={
        "id": "ID",
        "created_at": "–î–∞—Ç–∞",
        "status_label": "–°—Ç–∞—Ç—É—Å",
        "cost": "–°–ø–∏—Å–∞–Ω–∏–µ",
        "model_name": "–ú–æ–¥–µ–ª—å",
        "prediction": "–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ",
    })


@st.cache_data(show_spinner=False)
def transactions_to_df(items: List[dict]) -> pd.DataFrame:
    """–ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç —Å–ø–∏—Å–æ–∫ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π –≤ DataFrame."""
    if not items:
        return pd.DataFrame()

    df = pd.DataFrame(items)


    if "created_at" in df.columns:
        df["created_at"] = pd.to_datetime(df["created_at"]).dt.strftime("%Y-%m-%d %H:%M")

    if "status" in df.columns:
        df["status_label"] = df["status"].apply(lambda s: status_label(str(s)))

    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–æ–ª–æ–Ω–∫–∏
    guess_type = "type" if "type" in df.columns else ("operation_type" if "operation_type" in df.columns else None)
    guess_amount = "amount" if "amount" in df.columns else ("value" if "value" in df.columns else None)

    cols = [c for c in [
        "id", "created_at", "status_label", guess_type, guess_amount
    ] if c and c in df.columns]

    rename = {
        "id": "ID",
        "created_at": "–î–∞—Ç–∞",
        "status_label": "–°—Ç–∞—Ç—É—Å",
    }
    if guess_type:
        rename[guess_type] = "–¢–∏–ø"
    if guess_amount:
        rename[guess_amount] = "–°—É–º–º–∞"

    return df[cols].rename(columns=rename)


@st.cache_data(show_spinner=False)
def calculate_statistics(requests: List[dict]) -> Dict[str, Any]:
    """–í—ã—á–∏—Å–ª—è–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ –∑–∞–ø—Ä–æ—Å–∞–º."""
    if not requests:
        return {
            "total": 0,
            "success": 0,
            "pending": 0,
            "failed": 0,
            "total_cost": 0
        }

    total = len(requests)
    success = sum(1 for x in requests if str(x.get("status", "")).lower() in ("success", "completed", "done"))
    pending = sum(1 for x in requests if str(x.get("status", "")).lower() in ("pending", "processing", "in_progress"))
    failed = sum(1 for x in requests if str(x.get("status", "")).lower() in ("fail", "error", "failed"))
    total_cost = sum(float(x.get("cost", 0)) for x in requests if x.get("cost"))

    return {
        "total": total,
        "success": success,
        "pending": pending,
        "failed": failed,
        "total_cost": total_cost,
        "success_rate": (success / total * 100) if total > 0 else 0
    }
